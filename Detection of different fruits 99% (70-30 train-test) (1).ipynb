{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import os\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224 \n",
    "train_data_dir = '../input/fruits/fruits-360/Training'\n",
    "validation_data_dir = '../input/fruits/fruits-360/Test'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "fruit_list = [\"Kiwi\", \"Banana\", \"Orange\",\n",
    "                \"Limes\", \"Lemon\",\"Pear\", \"Pear 2\", \"Papaya\",\"Apple Golden 1\",\"Apple Golden 2\",\n",
    "              \"Apple Golden 3\",\"Apple Braeburn\",\"Apple Red 1\",\"Apple Red 2\",\"Apple Red 3\",\n",
    "              \"Apple Red Yellow 1\",\"Apple Red Yellow 2\"\n",
    "              \"Banana\",\"Banana Red\",\"Banana Lady Finger\",\"Corn\",\"Corn Husk\",\"Mango\",\"Mango Red\",\n",
    "              \"Strawberry\",\"Strawberry Wedge\", \"Pineapple\", \"Pomegranate\",\n",
    "              \"Tomato 1\",\"Tomato 2\",\"Tomato 3\",\"Tomato 4\",\"Tomato Heart\",\"Tomato not Ripened\",\n",
    "              \"Watermelon\"\n",
    "             ]\n",
    "print(len(fruit_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17187 images belonging to 34 classes.\n",
      "Found 5747 images belonging to 34 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = ImageDataGenerator(rescale=1/255, validation_split=0.3)    \n",
    "\n",
    "train_generator = image_generator.flow_from_directory(train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    classes=fruit_list,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = image_generator.flow_from_directory(validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    classes=fruit_list,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kiwi': 0,\n",
       " 'Banana': 1,\n",
       " 'Orange': 2,\n",
       " 'Limes': 3,\n",
       " 'Lemon': 4,\n",
       " 'Pear': 5,\n",
       " 'Pear 2': 6,\n",
       " 'Papaya': 7,\n",
       " 'Apple Golden 1': 8,\n",
       " 'Apple Golden 2': 9,\n",
       " 'Apple Golden 3': 10,\n",
       " 'Apple Braeburn': 11,\n",
       " 'Apple Red 1': 12,\n",
       " 'Apple Red 2': 13,\n",
       " 'Apple Red 3': 14,\n",
       " 'Apple Red Yellow 1': 15,\n",
       " 'Apple Red Yellow 2Banana': 16,\n",
       " 'Banana Red': 17,\n",
       " 'Banana Lady Finger': 18,\n",
       " 'Corn': 19,\n",
       " 'Corn Husk': 20,\n",
       " 'Mango': 21,\n",
       " 'Mango Red': 22,\n",
       " 'Strawberry': 23,\n",
       " 'Strawberry Wedge': 24,\n",
       " 'Pineapple': 25,\n",
       " 'Pomegranate': 26,\n",
       " 'Tomato 1': 27,\n",
       " 'Tomato 2': 28,\n",
       " 'Tomato 3': 29,\n",
       " 'Tomato 4': 30,\n",
       " 'Tomato Heart': 31,\n",
       " 'Tomato not Ripened': 32,\n",
       " 'Watermelon': 33}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 222, 222, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 109, 109, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 34)                17442     \n",
      "=================================================================\n",
      "Total params: 934,594\n",
      "Trainable params: 934,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([  ## initializing and making an empty model with sequential\n",
    "  \n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution layer\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224,3)), ## image input shape is 300x300x3 \n",
    "                           \n",
    "\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2,2),    # doing max_pooling\n",
    "    tf.keras.layers.Dropout(0.2),         #16 neurons in this layer\n",
    "\n",
    "  \n",
    "    # The second convolution layer\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'), # another layer with 32 neurons\n",
    "    tf.keras.layers.MaxPooling2D(2,2),     # doing max_pooling\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "\n",
    "    # The third convolution layer\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), # another layer with 64 neurons\n",
    "    tf.keras.layers.MaxPooling2D(2,2),        # doing max_pooling\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "\n",
    "\n",
    "    # The fourth convolution layer\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), # another layer with 64 neurons\n",
    "    tf.keras.layers.MaxPooling2D(2,2),          # doing max_pooling\n",
    "    tf.keras.layers.Dropout(0.2),  \n",
    "\n",
    "\n",
    "    # The fifth convolution \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), # another layer with 64 neurons\n",
    "    tf.keras.layers.MaxPooling2D(2,2),        # doing max_pooling\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "\n",
    "\n",
    "    tf.keras.layers.Flatten(),  # reducing layers arrays \n",
    "    tf.keras.layers.Dense(512, activation='relu'), # 512 neuron hidden layer\n",
    "\n",
    "\n",
    "\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for ('normal') clas and \n",
    "    # 1 for ('pneumonia') class\n",
    "    tf.keras.layers.Dense(34, activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "# to get the summary of the model\n",
    "model.summary()  # summarising a model\n",
    "\n",
    "# configure the model for traning by adding metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import ModelCheckpoint\n",
    "# filepath=\"weights.best.hdf5\" # mentioning a file for saving checkpoint model in case it gets interrupted\n",
    "\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# ## we marked filepath, monitor and mentioned to save best model only \n",
    "\n",
    "\n",
    "# callbacks_list = [checkpoint]  # customising model to save checkpoints\n",
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        val_acc = logs[\"val_accuracy\"]\n",
    "        if val_acc >= self.threshold:\n",
    "            self.model.stop_training = True\n",
    "            print(\"\\nReq acc is reached\")\n",
    "my_callback = MyThresholdCallback(threshold=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001),\n",
    "              metrics = ['accuracy']) \n",
    "print('Compiled !')    # compiling mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 1.7575 - accuracy: 0.4717 - val_loss: 1.1072 - val_accuracy: 0.6826\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.4952 - accuracy: 0.8470 - val_loss: 0.8082 - val_accuracy: 0.7378\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.2501 - accuracy: 0.9197 - val_loss: 0.7599 - val_accuracy: 0.7670\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.1776 - accuracy: 0.9477 - val_loss: 1.2536 - val_accuracy: 0.5925\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.1559 - accuracy: 0.9603 - val_loss: 0.8142 - val_accuracy: 0.7435\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.0933 - accuracy: 0.9778 - val_loss: 0.5944 - val_accuracy: 0.8571\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.1109 - accuracy: 0.9749 - val_loss: 0.4247 - val_accuracy: 0.8734\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0942 - accuracy: 0.9778 - val_loss: 0.3407 - val_accuracy: 0.9058\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.1049 - accuracy: 0.9775 - val_loss: 0.3833 - val_accuracy: 0.9172\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0725 - accuracy: 0.9854 - val_loss: 1.6964 - val_accuracy: 0.7792\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0791 - accuracy: 0.9796 - val_loss: 1.6673 - val_accuracy: 0.7817\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 11s 50ms/step - loss: 0.0764 - accuracy: 0.9839 - val_loss: 0.3691 - val_accuracy: 0.9286\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0700 - accuracy: 0.9848 - val_loss: 0.5188 - val_accuracy: 0.8929\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0525 - accuracy: 0.9897 - val_loss: 0.3872 - val_accuracy: 0.9286\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.0755 - accuracy: 0.9880 - val_loss: 0.3647 - val_accuracy: 0.9261\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0461 - accuracy: 0.9892 - val_loss: 1.2071 - val_accuracy: 0.8831\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0927 - accuracy: 0.9880 - val_loss: 0.8936 - val_accuracy: 0.9156\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 10s 47ms/step - loss: 0.1074 - accuracy: 0.9863 - val_loss: 0.6410 - val_accuracy: 0.9131\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.0786 - accuracy: 0.9862 - val_loss: 0.5765 - val_accuracy: 0.8920\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0759 - accuracy: 0.9877 - val_loss: 0.5246 - val_accuracy: 0.9318\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - 9s 42ms/step - loss: 0.0796 - accuracy: 0.9898 - val_loss: 1.0429 - val_accuracy: 0.8969\n",
      "Epoch 22/30\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.0665 - accuracy: 0.9912 - val_loss: 0.6135 - val_accuracy: 0.9294\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0880 - accuracy: 0.9880 - val_loss: 1.3736 - val_accuracy: 0.8856\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.1006 - accuracy: 0.9889 - val_loss: 1.3005 - val_accuracy: 0.8929\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - 10s 47ms/step - loss: 0.0703 - accuracy: 0.9901 - val_loss: 1.1641 - val_accuracy: 0.8847\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0869 - accuracy: 0.9901 - val_loss: 0.8534 - val_accuracy: 0.9221\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0954 - accuracy: 0.9892 - val_loss: 1.8280 - val_accuracy: 0.8677\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0630 - accuracy: 0.9930 - val_loss: 0.8747 - val_accuracy: 0.9026\n",
      "Epoch 29/30\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0952 - accuracy: 0.9880 - val_loss: 1.5798 - val_accuracy: 0.9164\n",
      "Epoch 30/30\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.1209 - accuracy: 0.9904 - val_loss: 1.1564 - val_accuracy: 0.9196\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    steps_per_epoch = 21457//(100),\n",
    "    epochs = 30,\n",
    "    shuffle=True,\n",
    "    validation_data = validation_generator,\n",
    "    callbacks=[my_callback],\n",
    "    validation_steps = 7777 // 100\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
